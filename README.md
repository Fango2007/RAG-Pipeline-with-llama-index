:rocket: 
# RAG Pipeline project 

**Just a small project to get the hang of Llama-index and related packages to implement a personal RAG solution based on a local llm hosted by Ollama.**

## Features
* Chat interface
* Agent router to determine the best option for the vector index (Summary or not)
* File upload
* Persistent vector index
* Reranking
* Model selection (required to run then with Ollama)
* God mode :
    * Assessing the relevance of the answer (-> framework TrueEra)
    * Selecting the temperature
